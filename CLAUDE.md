We are developing an application based on requirements ai-big5-stories.md and using TRACKER-LOG.md to keep tarck of status and periodically update with any changes to approach, progress, results of testing, key decisions etc. 
At this stage, all key functionalities for Phase 2 have been completed
We are now ready to add web dashbaord for database analysis
But, before we do that I wanted to come up with a plan to add some added functionality
1. Would like to add a flag to each use case based on whether it is a Gen AI use case or not. Open question, should this be done as part of data ingestion pipeline or added later?
2. How should we handle any updates?  For example, if there are missing values - should we have a process for a manual update?
3. How about some other data quality steps?  Like for example, we can spot check and update if the company name has been captured wrongly etc.
Lets discuss and come up with a plan before we implement anything

